---
title: "Financial Data Analysis for Time Series Forecasting"
date: 2025-10-28 12:00:00 +0900
categories: [iSME, seminar]
tags: [FTS-Diffusion, scale-invariance, irregularity, time-series, DTW, SISC, KMeans++, diffusion, DDPM, AE, Markov, augmentation]
math: true
permalink: /notes/financial-time-series/fts-diffusion/
---

# Financial Data Analysis for Time Series Forecasting

## Target Paper
[1] Huang, Hongbin, Minghua Chen, and Xiao Qiao. "Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns." *ICLR* 2024.  
[2] Ho, Jonathan, Ajay Jain, and Pieter Abbeel. "Denoising diffusion probabilistic models." *NeurIPS* 2020.  
[3] Sohl-Dickstein, Jascha, et al. "Deep unsupervised learning using nonequilibrium thermodynamics." *ICML* 2015.

---

## Introduction

금융 시장 예측 모델의 학습 과정에서 **데이터 부족**은 주요 문제. 2024 OIBC Challenge(제주 전력 하루전시장 가격 예측)에서도 주어진 데이터는 **2024-03부터 현재까지 약 8개월**에 불과. 데이터가 충분해지는 시점에는 가격이 **안정화**되기에 ML/DL 기반 기대 가치가 크지 않음. 또한 금융 시계열은 과거 기록 위주라 **인위적 실험 기반 데이터 수집이 어렵다**는 한계.

이를 해결하기 위해 **금융 시장 데이터 증강** 접근이 제안됨. 하지만 금융 시계열의 도메인 지식인 **scale-invariance**와 **irregularity** 때문에 기존 증강 기법으로는 합리적 결과를 얻기 어려움.

- **Scale-Invariance:** 패턴(연속된 데이터 값들의 그룹; segment)끼리 **기간 또는 값의 스케일 차이를 무시**하면 개형이 유사함. 패턴들은 기간과 크기는 다양하지만 **유한 개의 개형**으로 표현 가능. 동일 개형이 **짧은 기간·작은 변동**으로도, **긴 기간·큰 변동**으로도 나타남. (투자 심리 기반 가격 차트 해석에서 마루/골 반복 이후 반등의 끝자락이 규모와 기간이 달라도 특정 개형으로 설명되는 예시.)
- 이는 제조 신호 등 일반 시계열의 **Scale-Dependence**와 다른 **금융 데이터만의 특성**.
  <img width="1017" height="284" alt="image" src="https://github.com/user-attachments/assets/875b2691-f5c6-4c54-96cd-6196e0f75071" />

- **Irregularity:** 특정 패턴이 **언제 재등장할지 모름**. 일반 시계열의 **Regularity**(주기·규칙 반복)와 반대. Regularity는 FFT 같은 주파수 분해 전처리의 근거. 반대로 금융 시계열은 **일정치 않은 간격**으로 패턴 등장 → Irregularity.

<img width="972" height="301" alt="image" src="https://github.com/user-attachments/assets/b9b834e9-9c01-4aea-8caf-43f8311fb02f" />


> 한 예시에서는 작은 코끼리 → 중간 코끼리로 **개형은 비슷**(Scale-Invariance)하나 **크기/기간은 다름**, 이후 더 큰 코끼리가 **올지 불확실**(Irregularity).
> 
<img width="576" height="356" alt="image" src="https://github.com/user-attachments/assets/3ef07c35-4c30-470c-a6c4-4aa3d1473308" />

본 논문은 두 특성을 반영해 **세 모듈**로 구성된 **FTS-Diffusion** 프레임워크 제안:
1) **Pattern Recognition Module** — 시계열에서 주요 **패턴 개형·크기 추출**(전처리).  
2) **Pattern Generation Module** — 전처리 결과로 **패턴 분포 추정·생성**(개형 $p$, 기간 $\alpha$, 값 크기 $\beta$ 조건).  
3) **Pattern Evolution Module** — $\{p,\alpha,\beta\}$를 상태로 하는 **마코프 체인(‘개구리 점프’)** 기반 **순차적 패턴 과정** 추정.

---

## Pattern Recognition Module

**SISC 알고리즘**으로 전체 시계열을 $m$개의 패턴 개형으로 분할하고, 이를 $K$개의 **고유 대표 패턴 개형**에 할당(군집화). 그림에서는 $x_1,x_2,x_3$ 표기를 썼지만, 여기서는 **$s_1,s_2,s_3$**로 칭함.

### 1) 클러스터 중심 초기화(K-Means++ 유사)
- 전체 길이가 $T$인 시계열에서 지정 길이 $\ell_{\max}$로 **중심 후보군**을 $T-\ell_{\max}+1$개 생성.  
  후보 창: $X_{t:t+\ell_{\max}}$.
- 무작위로 첫 중심 $p_1$ 선택. 이후 **현 중심들과의 거리가 먼** 패턴이 다음 중심으로 선택될 확률을 높여 샘플링 → $p_2,\dots,p_K$.
- $K$개 중심 선택 후 K-Means 진행.

### 2) 패턴 최적 길이 결정 및 분할
현재 패턴 시작 시점 $t$에서 **길이–대표 개형**을 동시 탐색:
$$
\ell_m^* \;=\;
\arg\min_{\substack{p\in \mathcal{P}\\ \ell\in[\ell_{\min},\,\ell_{\max}]}}
d\!\big(X_{t:t+\ell},\,p\big).
$$

여기서 $d(\cdot,\cdot)$는 **DTW 거리**. 단, DTW는 기간/값 크기 차이를 자동 보정하지 않으므로, SISC는 DTW 이전에 다음 **정규화**를 수행:
- **기간 스케일:** $\alpha_m=\ell_m^*$
- **값 스케일:** $\beta_m=\max(s_m)-\min(s_m)$
- $s_m:=X_{t:t+\ell_m^*}$를 $\alpha_m,\beta_m$로 정규화하여 **개형만** 비교

> **DTW**: 두 시계열 $X=(x_1,\dots,x_m)$, $Y=(y_1,\dots,y_n)$의 시간축을 **뒤틀어** 정렬 거리를 최소화하는 알고리즘. 유클리디안과 달리 **속도·길이 차**에 강건.

### 3) 군집화 반복(K-Means)
- 모든 후보 길이 $\ell$과 대표 개형 $p_k$에 대해 DTW 거리 $d(s_m,p_k)$를 계산, **가장 작은 거리**를 주는 $\ell_m^*$ 선택 → $s_m=X_{t:t+\ell_m^*}$를 **패턴(segment)**으로 추출.
- 각 $s_m$을 가장 가까운 중심 $p_k^*$에 할당, 중심 업데이트, 수렴까지 반복.

**최종 분해 형태:**  
$$
s_m \;=\; \big\{\,p_k,\ \alpha_m,\ \beta_m,\ \mathrm{normalized}(s_m)\,\big\}.
$$

---

## Pattern Generation Module

SISC로 추출한 **centroid**를 통해 학습 시계열의 **패턴 개형·크기**를 추출하고, 개형 기준으로 **군집화**했다고 가정. 가정: **추출된 패턴 개형**이 금융 정보의 **핵심**. 목표: **개형이 정해졌을 때**, 그 군집의 **조건부 분포**에서 다양한 기간/값 크기를 갖는 **합리적 패턴**을 생성.

- **DDPM**(Denoising Diffusion Probabilistic Model)로 **고정 길이의 개형 분포** 학습  
- **AE**(AutoEncoder)로 **패턴 크기 조절** 학습

### AE 구조
- **Encoder:** 원본 segment $s_m$ 입력 → 기간·값이 정규화된 **represent** $s^0_m$ 출력.  
  기간은 입력 차원에 대응 → Encoder가 **정해진 출력 차원**에 정규화된 값을 내도록 학습.
- **Decoder:** (Diffusion이 생성한) **개형**과 $(\alpha_m,\beta_m)$를 입력으로 받아 **원 스케일** segment 복원.

### Diffusion(개형 생성)
- **입력:** $s^0_m$  
- **아이디어:** 점진적 노이즈 추가/제거로 **개형 분포**의 조건부 생성.  
- **결과:** 주어진 개형과 유사한 패턴 개형을 생성하는 **pattern-conditioned Diffusion**.

> **손실 구성 요지:**  
> 앞쪽 term은 **Decoder의 스케일 복구 오차**(원본 $s_m$과의 차),  
> 뒤쪽 term은 **DDPM의 시점별 노이즈 복구 오차**(입력 $s^0_m$ 기준).

---

## DDPM (Denoising Diffusion Probabilistic Models)

여기서 사용하는 $\beta$는 위의 **magnitude factor $\beta_m$와 별개**(표기 충돌 주의).

**확산(정방향) 모델:** 각 시점에 **작은 가우시안 노이즈**를 더해 데이터 분포를 **단순 분포**로 변환.  
**역방향(복원) 모델:** 단순 분포에서 시작해 노이즈를 제거하며 **원본 분포**를 재현.

### 정방향(노이즈 추가; 마코프 체인)
시간 $t$에서
$$
X_t \mid X_{t-1}
\;=\;
\sqrt{1-\beta_{t-1}}\;X_{t-1}
\;+\;
\sqrt{\beta_{t-1}}\; \mathcal{N}(0,\mathbf{I}).
$$
$\alpha_t := 1-\beta_t$, $\bar\alpha_t := \prod_{i=1}^t \alpha_i$라 두면,
$$
X_t \mid X_{t-2}
\;=\;
\sqrt{\alpha_t\alpha_{t-1}}\;X_{t-2}
\;+\;
\sqrt{1-\alpha_t\alpha_{t-1}}\;\mathcal{N}(0,\mathbf{I}),
$$
일반화하면
$$
X_t \mid X_0
\;=\;
\sqrt{\bar\alpha_t}\;X_0
\;+\;
\sqrt{1-\bar\alpha_t}\;\mathcal{N}(0,\mathbf{I}).
$$

### 역방향(복원) 관련 유도(개념 그대로 유지)
조건부 분포 $X_{t-1}\mid(X_t,X_0)$의 기댓값 유도(원문 서술을 수식으로 정리):
\[
\begin{aligned}
\mathbb{E}[X_{t-1}\mid(X_t,X_0)]
&=
\frac{\sqrt{\alpha_t}\,(1-\bar\alpha_{t-1})}{\beta_t (1-\bar\alpha_t)}\,\big(X_t\mid X_0\big)
+
\frac{\sqrt{\alpha_{t-1}}\,\beta_t}{1-\bar\alpha_t}\,X_0 \\
&=
\frac{1}{\sqrt{\alpha_t}}
\left(
X_t\mid X_0
-
\frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}}\,\mathcal{N}(0,\mathbf{I})
\right).
\end{aligned}
\]
여기서 $\sqrt{1-\bar\alpha_t}\,\mathcal{N}(0,\mathbf{I})$는 $X_t\mid X_0$에서 **1~$t$ 시점까지 가해진 노이즈**.  
따라서 $t$시점 실현치 $x'_t\mid x'_0=\sqrt{\bar\alpha_t}\,x'_0+\sqrt{1-\bar\alpha_t}\,\epsilon$의 **노이즈 $\epsilon$**을 알면 $x'_{t-1}$의 MLE를 얻을 수 있음.

- **학습(Algorithm 1 개념):** 모델 $\epsilon_\theta$는 입력 $(x'_t,t)$에 대해 **해당 시점의 노이즈 $\epsilon$을 추정**하도록 학습.  
- **추론(Algorithm 2 개념):** $x'_T$에서 시작 → $\epsilon_\theta$로 노이즈 예측 → $x'_{T-1}$ 샘플 → 반복 → $x'_0$ 생성. 분산 $\sigma_t$는 하이퍼파라미터.

---

## Pattern Evolution Module

**목표:** $\{p,\alpha,\beta\}$를 사상으로 한 **마코프 체인(‘개구리 점프’)**으로 **연속 패턴 과정** 추정.  
샘플링된 $\{p,\alpha,\beta\}$는 **직전 시점 패턴**에만 종속. **패턴 전이 확률**
$$
Q\big(\{p_j,\alpha_j,\beta_j\}\mid\{p_i,\alpha_i,\beta_i\}\big)
$$
을 추정해 연속 패턴 간 **동적 관계**를 모델링, **순차 샘플링**으로 시계열의 **연속성·일관성** 보존.

- **$p$:** 학습 데이터의 **대표 패턴** 중 하나로 분류  
- **$\alpha,\beta$:** 각각 **기간·크기 스케일**을 회귀  
- **손실 함수 설계:** 분류($p$)는 CE, 회귀($\alpha,\beta$)는 MSE로 구성(원문 취지 그대로)

---

## Conclusion

위 **3개 모듈**을 합쳐 전체 아키텍처는 다음과 같음.

1) 학습 데이터 $X$를 **SISC**로 **패턴 개형·크기**로 분해.  
2) 이를 활용해 **Pattern Generation Module**이 **{개형, 크기} 하의 패턴 생성**을 학습.  
3) **Pattern Evolution Module**은 **개구리 점프(마코프)**로 **패턴 이산 확률 과정** 학습.  
4) Evolution에서 다음 시점의 $\{p,\alpha,\beta\}$를 **샘플링**하고, 이를 Generation의 **입력**으로 사용해 패턴 **생성**.

**총평:** 금융 시계열의 **Scale-Invariance & Irregularity**를 명시적으로 정의하고 이를 반영하려는 **합리적 시도**. 다만 과업이 **현실 유사 데이터 증강**이기 때문에 **예측 정확도 향상** 측면의 효과는 제한적.  
실험 비교에서, 다른 생성형 증강은 **증강량이 많아질수록 과적합**을 유발. 제안법은 **과적합은 덜**하지만 **성능 향상도 두드러지지 않음**. 이는 증강 데이터가 **현실 금융 분포를 정확히 근사**했다기보다, **불규칙 패턴**을 담아 **노이즈 강건성**을 높였기 때문으로 해석.  
서론에서 언급했듯 **예측 성능** 향상 목적에는 의문. 대신 **스트레스 테스트/리스크 시나리오/로버스트 학습** 용도에는 가치.

